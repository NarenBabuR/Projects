{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# In most of NLP cases, import TSV data because there may ',' in the sentence itself.\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3) # quoting = 3, to neglect the \"(Double quotes) in the data which may cause any anamoloy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naren/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/naren/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/naren/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/naren/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Process\n",
    "# This can also be implemeted with CountVectorizer, but doing it manually gives us more control and customization\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "corpus= []\n",
    "for i in range(0,1000):\n",
    "    # First parameter is what we want to remove. By adding ^ we tell what we don't want to remove \n",
    "    # Second parameter - Removed character will be replaced by a space to avoid problem of having two parts stuck together\n",
    "    # Third parameter to specify where to do the operation\n",
    "    review= re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "\n",
    "    # Converting all words to lower case\n",
    "    review= review.lower()\n",
    "\n",
    "    # Object created for stemming\n",
    "    ps= PorterStemmer()\n",
    "\n",
    "    # Removing non-significant words and apllying stemming\n",
    "    review= review.split() # to split the whole instance into seperate words\n",
    "    review= [ps.stem(word) for word in review if not word in set(stopwords.words('english'))] # set() to work much faster\n",
    "\n",
    "    # To join back the individual words into a sentence\n",
    "    review= ' '.join(review) # ' ' to insert the space in-between the words   \n",
    "    \n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv= CountVectorizer(max_features= 1500) #max_feature=1500 gives most relevant words (i.e) top 1500 words. \n",
    "X= cv.fit_transform(corpus).toarray()\n",
    "y= dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naren/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Naive Bayes to the Training set\n",
    "# Other than Gaussian other good ones for NLP include: CART, C5.0, Maximum Entropy\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Precision (measuring exactness) = TP / (TP + FP)\n",
    "Recall (measuring completeness) = TP / (TP + FN)\n",
    "F1 Score (compromise between Precision and Recall) = 2 * Precision * Recall / (Precision + Recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 42]\n",
      " [12 91]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
